{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix weird branch stuff\n",
    "#download libraries\n",
    "%pip install Pillow\n",
    "%pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: Get training data\n",
    "\n",
    "#import images\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "#count files in a folder\n",
    "def count_files_in_folder(folder_path):\n",
    "    folder = Path(folder_path)\n",
    "    return sum(1 for item in folder.iterdir() if item.is_file())\n",
    "\n",
    "#set folder path to l_training data\n",
    "folder_path = 'data'\n",
    "num_files = count_files_in_folder(folder_path)\n",
    "\n",
    "imagelib = []\n",
    "\n",
    "#store all files into library to use for data training\n",
    "for i in range(num_files):\n",
    "    imagelib.append(\"data/league_of_legends/img\" + str(i + 1) +\".png\")\n",
    "\n",
    "#verify correct number of files\n",
    "print(len(imagelib))\n",
    "\n",
    "#open image with line below\n",
    "#image = Image.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Load Data\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build data pipeline\n",
    "data = tf.keras.utils.image_dataset_from_directory(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access generator from data pipeline\n",
    "#data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizes image to fit the batch, \n",
    "#batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show array of league of legends, vs destiny (we can tell by the sample of images that league is 1 and destiny is 0)\n",
    "#class 1 = league\n",
    "#class 0 = destiny\n",
    "#batch[0] is all the images\n",
    "#batch[1] are labels\n",
    "#batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 preprocess data\n",
    "#applies the scaling while the data is being loaded\n",
    "data = data.map(lambda x,y: (x/255, y))\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize data with matplotlib\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training, validation and testing\n",
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2) + 1\n",
    "test_size = int(len(data)*.1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure that values add up into the length of the batches\n",
    "train_size+val_size+test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure data is shuffled before, in this case we already have shuffled the data with initial batch\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential models great if you have one data input and one data output\n",
    "#functional api is better if you have multiple inputs and multiple outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#Conv2d is a 2d convolution layer (spatial convolution over images)\n",
    "#maxpooling2d condenses all the values in a region and returns max\n",
    "#Flatten turns convolution into a format that dense can understand\n",
    "#dropout for regularization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
